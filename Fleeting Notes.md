I wonder how currently implementation of AI works? Currently it isn't thinking, but rather it's trying to make it's output look like something it's seen before. Basically making it find and replicate patterns, but this isn't like the human mind. It's basically memorizing answers and then trying to make a response that looks like it's memory

The attention mechanisms puts weights on the input determining which parts are important and how it goes into the final response. It then uses this weight and mathematically output something that best represents the closes the response (thinking of mapping the actual output, onto something in the vector space of answers or something).

This however can be taken to the next level. Since this is basically like attention, we can use this attention to then create intuition. To form new from intuition (a lead/feeling), forming new ideas, then testing the idea and backtracking when it doesn't work? 

How would this work? If we try to mimic how the brightest minds are able to do this, we then use the information information extracted from an input, to then make a leap. To make a deduction. This is usually based off some reasoning ability justified through proofs and examples. Then testing this theory to then make something big.



